app name: sign language detector v2.1

what is this:
basically a python app that sees your hands and tells you what you're saying in sign language.
works with your webcam or you can upload a video file.
supports american sign language (asl) alphabets and some dynamic gestures like waving.

cool stuff it does:
- tracks your hands in real-time (uses mediapipe)
- tells you what letter you're signing (uses random forest ml model)
- reads your face too and tells you if you look happy, sad, angry etc
- works with uploaded videos:
  - supports mp4, avi, mov, mkv, webm
  - tracks hands properly now (no jittery mess) because we used video mode
  - lower thresholds for videos so it catches blurry hands better
  - has fallback geometry detection if the ML model gets confused
- translates sentences:
  - type out full sentences by signing letter by letter
  - waits for you to finish then auto-translates
- saves your history so you can see what you said later
- secure login/signup system (uses local sqlite db)
- dark mode ui that looks actually decent (pyside6/qt)
- new hybrid mode: recognizes both letters AND dynamic gestures at the same time (best for normal signing)

tech stack:
- python 3.x
- pyside6 (for the gui)
- opencv (to see stuff)
- mediapipe (to track hands and face)
- scikit-learn (for the smarts)
- sqlite (to save stuff)

how to run:
python main.py

folder structure:
main.py -> start here
config.py -> settings like camera id and thresholds
backend/ -> database stuff
detector/ -> all the computer vision magic (camera, hand tracking, face detect)
ml/ -> machine learning stuff (classifier, trainer)
ui/ -> all the windows and widgets
models/ -> where the trained brain lives
data/ -> training images

dev notes:
- the hand tracker for video files uses timestamps now, so it knows "frame 2 comes after frame 1" which makes tracking way smoother.
- we added a "heuristic classifier" which basically just checks finger positions with math properties. it's super reliable for simple stuff like pointing or fists.
- the video player connects to the same prediction logic as the camera, so everything works the same way.
- auto-translate timeout is configurable in config.py if you sign too slow or fast.

credits:
built by a very tired developer.
